A segurança da inteligência artificial (do termo em inglês AI Safety) é um campo interdisciplinar que se preocupa com a prevenção de acidentes, uso indevido ou outras consequências prejudiciais que possam resultar de sistemas de inteligência artificial (IA). Ela engloba a ética de máquinas e o alinhamento da IA ("AI alignment"), que visam tornar os sistemas de IA morais e benéficos. Também engloba questões técnicas, incluindo o monitoramento dos sistemas quanto a riscos e a sua alta confiabilidade. Além da pesquisa em inteligência artificial, ela envolve o desenvolvimento de normas e políticas que promovam a segurança.