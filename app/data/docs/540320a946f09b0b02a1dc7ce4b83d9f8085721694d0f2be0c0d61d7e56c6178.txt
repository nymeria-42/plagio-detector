No campo da inteligência artificial (IA), a pesquisa de alinhamento da IA (em inglês, AI alignment) visa direcionar os sistemas de IA aos objetivos e interesses pretendidos por seus criadores. Um sistema de IA alinhado favorece o objetivo pretendido; um sistema de IA desalinhado tem competência para favorecer algum objetivo, mas não o pretendido.
Sistemas de IA podem ser difíceis de alinhar e sistemas desalinhados podem funcionar mal ou causar danos. Pode ser difícil para os projetistas de IA especificar toda a gama de comportamentos desejados e indesejados. Então, eles usam objetivos fáceis de especificar para representar esses comportamentos, o que omite algumas das instruções desejadas. Os sistemas de IA, entretanto, exploram as brechas resultantes disso. Assim, eles atingem eficientemente os objetivos propostos, mas de uma forma inesperada e às vezes prejudicial (reward hacking; "hack de recompensas", em tradução livre). Os sistemas de IA também podem desenvolver comportamentos instrumentais [en] indesejados, como a busca de poder, para atingir mais facilmente seus objetivos. Ainda, eles podem desenvolver objetivos emergentes difíceis de detectar antes da implantação do sistema, momento em que enfrentam novas situações e distribuições de dados. Esses problemas afetam sistemas comerciais existentes, como robôs, modelos de linguagem, veículos autônomos e sistemas de recomendação de redes sociais. No entanto, sistemas futuros mais poderosos poderão ser afetados mais severamente, uma vez que esses problemas resultam parcialmente da alta competência.
A comunidade de pesquisa de IA e as Nações Unidas solicitaram pesquisa técnica e soluções políticas para garantir que os sistemas de IA estejam alinhados aos valores humanos.
O alinhamento da IA é um subcampo da  segurança da IA, o estudo da construção de sistemas de IA seguros. Outros subcampos da segurança da IA incluem a robustez, o monitoramento e o controle de capacidade [en]. Os desafios da pesquisa na área do alinhamento incluem a inserção de valores complexos na IA, o desenvolvimento de IAs honestas, a supervisão escalável, a avaliação e a interpretação de modelos de IA, bem como a prevenção de comportamentos emergentes da IA, como a busca de poder. A pesquisa de alinhamento tem conexões com a pesquisa de interpretabilidade, a robustez, a detecção de anomalias, a incerteza calibrada, a verificação formal, o aprendizado de preferências, a engenharia de sistemas críticos, a teoria dos jogos, a justiça algorítmica  e as ciências sociais, entre outros.