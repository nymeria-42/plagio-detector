Basilisco de Roko é o nome de um experimento mental que afirma que uma superinteligência artificial (IA) no futuro seria incentivada a criar uma simulação de realidade virtual para torturar qualquer pessoa que soubesse de sua possível existência, mas não contribuísse diretamente para seu avanço ou desenvolvimento, a fim de incentivar esse avanço. O experimento foi proposto em 2010 em um fórum de ciência chamado LessWrong. O nome do experimento de pensamento deriva do autor do artigo (Roko) e do basilisco, uma criatura mítica capaz de destruir inimigos com seu olhar. A comunidade que debateu o experimento proposto pelo usuário "Roko", apesar de pequena, possuia influência na indústria de tecnologia, por conta de seu interesse em transumanismo e singularidade tecnológica.
Embora a teoria tenha sido inicialmente descartada como nada além de conjectura ou especulação por muitos usuários do LessWrong, o cofundador do LessWrong, Eliezer Yudkowsky, registrou usuários que descreveram sintomas como pesadelos e colapsos mentais ao lerem a teoria, devido à estipulação de que apenas saber sobre a teoria tornava a pessoa vulnerável ao próprio basilisco. Isso levou a discussão sobre o basilisco no site a ser banida por cinco anos. No entanto, esses relatos foram posteriormente descartados como sendo exagerados ou inconsequentes, e a própria teoria foi descartada como absurda, inclusive pelo próprio Yudkowsky. Mesmo após o descrédito da postagem, ela ainda é usada como exemplo de princípios como probabilidade epistemológica e religião implícita. Ela também é considerada uma versão moderna da aposta de Pascal.